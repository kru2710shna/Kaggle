{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/group-by-having-count).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nQueries with **GROUP BY** can be powerful. There are many small things that can trip you up (like the order of the clauses), but it will start to feel natural once you've done it a few times. Here, you'll write queries using **GROUP BY** to answer questions from the Hacker News dataset.\n\nBefore you get started, run the following cell to set everything up:","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex3 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T23:00:45.560285Z","iopub.execute_input":"2023-09-30T23:00:45.560626Z","iopub.status.idle":"2023-09-30T23:00:46.094407Z","shell.execute_reply.started":"2023-09-30T23:00:45.560599Z","shell.execute_reply":"2023-09-30T23:00:46.093194Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearntools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binder\n\u001b[1;32m      3\u001b[0m binder\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearntools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mex3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetup Complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/learntools/sql/ex3.py:17\u001b[0m\n\u001b[1;32m     10\u001b[0m prolific_commenters_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m                            SELECT author, COUNT(id) AS NumPosts\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m                            FROM `bigquery-public-data.hacker_news.comments`\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m                            GROUP BY author\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m                            HAVING COUNT(id) > 10000\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m                            \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m query_job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(prolific_commenters_query)\n\u001b[0;32m---> 17\u001b[0m prolific_commenters_answer \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# (2) NumDeletedPosts\u001b[39;00m\n\u001b[1;32m     20\u001b[0m deleted_posts_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m                      SELECT COUNT(1) AS num_deleted_posts\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m                      FROM `bigquery-public-data.hacker_news.comments`\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m                      WHERE deleted = True\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m                      \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1695\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, date_as_object, max_results, geography_as_object)\u001b[0m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1615\u001b[0m     bqstorage_client: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     geography_as_object: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1622\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m \n\u001b[1;32m   1625\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;124;03m            :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1695\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[43mwait_for_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m   1697\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39mbqstorage_client,\n\u001b[1;32m   1698\u001b[0m         dtypes\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m         geography_as_object\u001b[38;5;241m=\u001b[39mgeography_as_object,\n\u001b[1;32m   1703\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_tqdm_helpers.py:88\u001b[0m, in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m     84\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m get_progress_bar(\n\u001b[1;32m     85\u001b[0m     progress_bar_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery is running\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_total, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1499\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_do_query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m job_retry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1497\u001b[0m         do_get_result \u001b[38;5;241m=\u001b[39m job_retry(do_get_result)\n\u001b[0;32m-> 1499\u001b[0m     \u001b[43mdo_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1502\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1503\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[1;32m   1504\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1489\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.do_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_do_query \u001b[38;5;241m=\u001b[39m retry_do_query\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job_retry \u001b[38;5;241m=\u001b[39m job_retry\n\u001b[0;32m-> 1489\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQueryJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;66;03m# Since the job could already be \"done\" (e.g. got a finished job\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;66;03m# via client.get_job), the superclass call to done() might not\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;66;03m# set the self._query_results cache.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:728\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    727\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AsyncJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/future/polling.py:261\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, retry\u001b[38;5;241m=\u001b[39mretry, polling\u001b[38;5;241m=\u001b[39mpolling)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n","\u001b[0;31mNotFound\u001b[0m: 404 Not found: Table bigquery-public-data:hacker_news.comments was not found in location US\n\nLocation: US\nJob ID: 5703500e-efd1-4eda-b166-2b0b04055989\n"],"ename":"NotFound","evalue":"404 Not found: Table bigquery-public-data:hacker_news.comments was not found in location US\n\nLocation: US\nJob ID: 5703500e-efd1-4eda-b166-2b0b04055989\n","output_type":"error"}]},{"cell_type":"markdown","source":"The code cell below fetches the `comments` table from the `hacker_news` dataset.  We also preview the first five rows of the table.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"comments\" table\ntable_ref = dataset_ref.table(\"comments\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"comments\" table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:20:28.862682Z","iopub.execute_input":"2023-04-23T10:20:28.863116Z","iopub.status.idle":"2023-04-23T10:20:29.701613Z","shell.execute_reply.started":"2023-04-23T10:20:28.863079Z","shell.execute_reply":"2023-04-23T10:20:29.700138Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        id    by author        time                   time_ts  text   parent  \\\n0  9734136  None   None  1434565400 2015-06-17 18:23:20+00:00  None  9733698   \n1  4921158  None   None  1355496966 2012-12-14 14:56:06+00:00  None  4921100   \n2  7500568  None   None  1396261158 2014-03-31 10:19:18+00:00  None  7499385   \n3  8909635  None   None  1421627275 2015-01-19 00:27:55+00:00  None  8901135   \n4  9256463  None   None  1427204705 2015-03-24 13:45:05+00:00  None  9256346   \n\n   deleted  dead  ranking  \n0     True  None        0  \n1     True  None        0  \n2     True  None        0  \n3     True  None        0  \n4     True  None        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>by</th>\n      <th>author</th>\n      <th>time</th>\n      <th>time_ts</th>\n      <th>text</th>\n      <th>parent</th>\n      <th>deleted</th>\n      <th>dead</th>\n      <th>ranking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9734136</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1434565400</td>\n      <td>2015-06-17 18:23:20+00:00</td>\n      <td>None</td>\n      <td>9733698</td>\n      <td>True</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4921158</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1355496966</td>\n      <td>2012-12-14 14:56:06+00:00</td>\n      <td>None</td>\n      <td>4921100</td>\n      <td>True</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7500568</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1396261158</td>\n      <td>2014-03-31 10:19:18+00:00</td>\n      <td>None</td>\n      <td>7499385</td>\n      <td>True</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8909635</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1421627275</td>\n      <td>2015-01-19 00:27:55+00:00</td>\n      <td>None</td>\n      <td>8901135</td>\n      <td>True</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9256463</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1427204705</td>\n      <td>2015-03-24 13:45:05+00:00</td>\n      <td>None</td>\n      <td>9256346</td>\n      <td>True</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Exercises\n\n### 1) Prolific commenters\n\nHacker News would like to send awards to everyone who has written more than 10,000 posts. Write a query that returns all authors with more than 10,000 posts as well as their post counts. Call the column with post counts `NumPosts`.\n\nIn case sample query is helpful, here is a query you saw in the tutorial to answer a similar question:\n```\nquery = \"\"\"\n        SELECT parent, COUNT(1) AS NumPosts\n        FROM `bigquery-public-data.hacker_news.comments`\n        GROUP BY parent\n        HAVING COUNT(1) > 10\n        \"\"\"\n```","metadata":{}},{"cell_type":"code","source":"# Query to select prolific commenters and post counts\nprolific_commenters_query = \"\"\"\n                            SELECT author, COUNT(1) AS NumPosts\n                            FROM `bigquery-public-data.hacker_news.comments`\n                            GROUP BY author\n                            HAVING COUNT(1) > 10000\n                            \"\"\"# Your code goes here\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(prolific_commenters_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nprolific_commenters = query_job.to_dataframe()\n\n# View top few rows of results\nprint(prolific_commenters.head())\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:20:53.980298Z","iopub.execute_input":"2023-04-23T10:20:53.981421Z","iopub.status.idle":"2023-04-23T10:20:54.868644Z","shell.execute_reply.started":"2023-04-23T10:20:53.981360Z","shell.execute_reply":"2023-04-23T10:20:54.867403Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"name":"stdout","text":"       author  NumPosts\n0        None    227736\n1     tptacek     33839\n2   anigbrowl     11395\n3  stcredzero     10092\n4       DanBC     12902\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_ProlificCommenters\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"q_1.solution()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:20:39.613020Z","iopub.execute_input":"2023-04-23T10:20:39.613449Z","iopub.status.idle":"2023-04-23T10:20:39.623367Z","shell.execute_reply.started":"2023-04-23T10:20:39.613411Z","shell.execute_reply":"2023-04-23T10:20:39.622291Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"questionId\": \"1_ProlificCommenters\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\nprolific_commenters_query = \"\"\"\n                            SELECT author, COUNT(1) AS NumPosts\n                            FROM `bigquery-public-data.hacker_news.comments`\n                            GROUP BY author\n                            HAVING COUNT(1) > 10000\n                            \"\"\"\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\nprolific_commenters_query = \"\"\"\n                            SELECT author, COUNT(1) AS NumPosts\n                            FROM `bigquery-public-data.hacker_news.comments`\n                            GROUP BY author\n                            HAVING COUNT(1) > 10000\n                            \"\"\"\n\n```"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2) Deleted comments\n\nHow many comments have been deleted? (If a comment was deleted, the `deleted` column in the comments table will have the value `True`.)","metadata":{}},{"cell_type":"code","source":"# Write your query here and figure out the answer\nquery_job=lient.query()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_deleted_posts = ____ # Put your answer here\n\n# Check your answer\nq_2.check()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_2.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keep Going\n**[Click here](https://www.kaggle.com/dansbecker/order-by)** to move on and learn about the **ORDER BY** clause.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}